{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados com IA \n",
    "\n",
    "### Utilizando Python, Scikit Learn e OpenAI API\n",
    "\n",
    "Isso é um trabalho sobre Análise de Dados com IA. Aqui mostrarei dois principais exemplos utilizando\n",
    "ferramentas do Python, uma vez que ela se apresenta como a mais viável para trabalhar com esse tema.\n",
    "\n",
    "Aqui estou utilizando o Jupyter Notebook, uma ferramenta que me permite intercalar células de Markdown\n",
    "com células de código Python, afim de produzir um conteúdo didático que pondera com excelência os textos\n",
    "didáticos e os exemplos de código. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro Exemplo: Análise Massiva e Previsão\n",
    "\n",
    "O primeiro exemplo se trata do uso da IA para fazer previsões com base em dados apresentados. <p>\n",
    "Aqui possuo uma planilha de clientes de uma instituição financeira. Essa instituição está com um\n",
    "evento que dará ao seus clientes confiáveis maior limite e oportunidades em seus serviços. Porém o número \n",
    "altíssimo de clientes torna a averiguação dos clientes uma tarefa extremamente cansativa e demorada para um ser humano. <p>\n",
    "Nesse contexto, a IA se apresenta como uma ferramenta capaz de analisar a qualidade dos clientes e decidir se eles se enquadram nos que serão beneficiados nesse evento. <p>\n",
    "Aqui utilizaremos duas principais ferramentas: \n",
    "\n",
    "### Pandas\n",
    "O Pandas é uma biblioteca muito conhecida pelos profissionais que trabalham com dados em quantidades diversas. Ele permite uma visualização, indexação e manipulação dos dados, excepcional para análises de todo tipo ou finalidade. <p>\n",
    "\n",
    "### Scikit Learn\n",
    "O Scikit Learn é uma biblioteca que provê diversas ferramentas para uso de modelos de linguagem. Aqui utilizaremos o codificador de dados, o banco de modelos, o divisor de dados para treino e teste para modelos e o verificador de acurácia do modelo. Tralaharemos em conjunto com o Pandas, utilizando ele para filtrar e indexar os dados que serão fornecidos aos modelos. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando passos para a execução:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo a passo\n",
    "# Passo 0 - Entender a empresa e o desafio da empresa\n",
    "# Passo 1 - Importar a base de dados\n",
    "import pandas as pd\n",
    "\n",
    "tabela = pd.read_csv(\"assets/clientes.csv\")\n",
    "\n",
    "display(tabela)\n",
    "\n",
    "# Score de crédito = Nota de crédito\n",
    "# Good = Boa\n",
    "# Standard = OK\n",
    "# Poor = Ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aqui fizemos uma análise inicial dos dados para entender como que a empresa administra e faz a gestão dos clientes, nosso próximo passo é preparar os dados com codificadores para que a IA possa processá-los e fazer as previsões.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela com Dados Brutos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2 - Preparar a base de dados para a Inteligência Artificial\n",
    "display(tabela.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela com Dados Convertidos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int -> numero inteiro\n",
    "# float -> numero com casa decimal\n",
    "# object -> texto\n",
    "\n",
    "# LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# profissao\n",
    "\n",
    "# cientista - 1\n",
    "# bombeiro - 2\n",
    "# engenheiro - 3\n",
    "# dentista - 4\n",
    "# artista - 5\n",
    "codificador_profissao = LabelEncoder()\n",
    "tabela[\"profissao\"] = codificador_profissao.fit_transform(tabela[\"profissao\"])\n",
    "\n",
    "\n",
    "# mix_credito\n",
    "codificador_credito = LabelEncoder()\n",
    "tabela[\"mix_credito\"] = codificador_credito.fit_transform(tabela[\"mix_credito\"])\n",
    "\n",
    "# comportamento_pagamento\n",
    "codificador_pagamento = LabelEncoder()\n",
    "tabela[\"comportamento_pagamento\"] = codificador_pagamento.fit_transform(tabela[\"comportamento_pagamento\"])\n",
    "\n",
    "display(tabela.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agora com os dados já codificados e adapatados para o trabalho dos modelos, podemos nos preocupar em preparar o ambiente de treino e teste das IAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y -> é a coluna da base de dados que eu quero prever\n",
    "y = tabela[\"score_credito\"]\n",
    "\n",
    "# x -> as colunas da base de dados que eu vou usar pra fazer a previsão\n",
    "x = tabela.drop(columns=[\"score_credito\", \"id_cliente\"])\n",
    "\n",
    "# separar em dados de treino e dados de teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "# Aqui ele pega os dados de entrada e divide as linhas das colunas entre dados de teste e treino,\n",
    "# assim retonando quatro variáveis que contém tais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aqui em cima nós preparamos a coluna na qual será feita a previsão e as colunas que serão utilizadas para fazer a previsão. Também importamos e configuramos o divisor de dados para treino e teste, onde fracionamos os dados entre dados de treino e dados de teste para o modelo. Agora temos que, de fato, treinar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que essas linhas de código foram apenas para fazer a separação dos dados, estamos basicamente usando essa função apenas para indicar como o modelo deverá entender os dados, e assim, trabalhar com eles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3 - Treinar a Inteligência Artificial -> \n",
    "# Criar o modelo: Nota de crédito: Boa, Ok, Ruim\n",
    "\n",
    "# Arvore de Decisão -> RandomForest\n",
    "# Nearest Neighbors -> KNN -> Vizinhos Próximos\n",
    "\n",
    "# importar a IA (Inteligencia Artificial)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# criar a IA\n",
    "modelo_arvoredecisao = RandomForestClassifier()\n",
    "modelo_knn = KNeighborsClassifier()\n",
    "\n",
    "# treinar a IA\n",
    "modelo_arvoredecisao.fit(x_treino, y_treino)\n",
    "modelo_knn.fit(x_treino, y_treino)\n",
    "\n",
    "# Vale ressaltar que nós passamos ambos os dados para a IA peceber como que esses mesmos dados \n",
    "# funcionam em conjunto. Sendo mais específico, ela precisa disso para saber como os outros dados \n",
    "# da tabela afetam os dados que serão previstos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Acima nós acabamos de importar os modelos que serão utilizados e usar a função fit do sklearn para passar os dados de treino e treinar o modelo. Depois podemos fazer os testes com os dados x (dados utilizados para a previsão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4 - Escolher qual o melhor modelo\n",
    "previsao_arvoredecisao = modelo_arvoredecisao.predict(x_teste)\n",
    "previsao_knn = modelo_knn.predict(x_teste)\n",
    "\n",
    "print(previsao_arvoredecisao)\n",
    "print(previsao_knn)\n",
    "print(\"\")\n",
    "\n",
    "# Explicando melhor, o modelo aqui recebe apenas os dados para a previsão, onde ele vai utilizá-los\n",
    "# para prever os dados a serem previstos.\n",
    "\n",
    "# acurácia\n",
    "from sklearn.metrics import accuracy_score\n",
    "acuracia_arvoredecisao = accuracy_score(y_teste, previsao_arvoredecisao)\n",
    "acuracia_knn = accuracy_score(y_teste, previsao_knn)\n",
    "\n",
    "print(\"Nota dos Testes:\")     \n",
    "print(\"-----------------------\")\n",
    "print(f\"Primeiro Modelo: {round((acuracia_arvoredecisao * 100), 1)}%\")\n",
    "print(f\"Segundo Modelo: {round((acuracia_knn * 100), 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aqui em cima utilizamos a função predict para criar os testes para os modelos com os dados x, e depois, importamos o verificador de acurácia do modelo e utilizamos os dados y para comparar as previsões da IA, e assim, determinar seu percentual de eficiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 5 - Usar o melhor modelo para fazer previsão de novos clientes\n",
    "# melhor modelo é o modelo_arvoredecisao\n",
    "\n",
    "# importar os novos clientes para fazer a previsao\n",
    "tabela_novos_clientes = pd.read_csv(\"assets/novos_clientes.csv\")\n",
    "\n",
    "# profissao\n",
    "tabela_novos_clientes[\"profissao\"] = codificador_profissao.fit_transform(\n",
    "    tabela_novos_clientes[\"profissao\"]\n",
    ")\n",
    "\n",
    "# mix_credito\n",
    "tabela_novos_clientes[\"mix_credito\"] = codificador_credito.fit_transform(\n",
    "    tabela_novos_clientes[\"mix_credito\"]\n",
    ")\n",
    "\n",
    "# comportamento_pagamento\n",
    "tabela_novos_clientes[\"comportamento_pagamento\"] = codificador_pagamento.fit_transform(\n",
    "    tabela_novos_clientes[\"comportamento_pagamento\"]\n",
    ")\n",
    "\n",
    "# Aqui nós redefinimos os codificadores com as mesmas variáveis para preparar os dados\n",
    "# para serem usados pelo modelo, mesmo processo de antes, utilizando LabelEncoder.\n",
    "\n",
    "display(tabela_novos_clientes)\n",
    "\n",
    "nova_previsao = modelo_arvoredecisao.predict(tabela_novos_clientes)\n",
    "\n",
    "print(nova_previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para concluir, utilizamos o modelo que se saiu melhor nos testes para prever e determinar o clientes que se encaixam nos requisitos do evento. Em uma aplicação profissional a tabela de novos clientes seria muito maior, tornando o treinamento mais necessário, mas nada muito complicado. Com o modelo treinado ele pôde ser aplicado com excelência para determinar os clientes. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Exemplo: Geração de Relatórios por meio de prompt\n",
    "\n",
    "A segundo exemplo trabalha em conjunto com o primeiro. Lá, nós treinamos e utilizamos os modelos para processar e prever dados, aqui vamos urilizar ferramentas de prompt para criação de relatórios. <p>\n",
    "Pois bem, vamos supor que a IA tenha terminado suas previsões e retornado aquele array das previsões que ela fez. A empresa necessita uma maneira mais legível e compreensível de ver esses retornos do modelo. <p>\n",
    "Aqui, a IA novamente facilitará a manipulação de dados massivos gerando relatórios bem mais legíveis para que possamos compreender melhor o que o processamento inicial significa.. <p>\n",
    "Aqui utilizaremos duas novas ferramentas: \n",
    "\n",
    "### OpenAI API\n",
    "A API da OpenAI é uma ferramenta que pode ser usada em várias linguagem de programação, incluindo ferramentas como cURL. Essa API te oferece múltiplos serviços para trabalhar com os modelos aprimorados do ChatGPT, permitindo que suas funcionalidades sejam integradas a outros algoritmos e códigos desenvolvidosm, desde que você possua créditos na sua API Key. <p>\n",
    "\n",
    "### Plotly\n",
    "O Plotly é uma ferramenta usada por veteranos na área de ciência de dados, trata-se de uma ferramenta um pouco mais técnica que o PowerBI, mas que funciona de maneira semelhante. Ela possibilita a criação de gráficos e dashboards, além d possuir integração com o Pandas para análise de dados massivos que não precisem de processamento inteligente. <p>\n",
    "\n",
    "### DotEnv\n",
    "O DotEnv ou dotenv, é uma tecnologia simples porém excelente para desenvolvimento de projetos que necessitem de dados sensíveis. Ele permite salvar esses dados em um arquivo .env, que será ignorado no deploy ou versionamento e só será utilizado na compilação do projeto. O dotenv possui ferramentas para gerir e extrair informações desse arquivo. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os dados a serem utilizados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_clientes = tabela[\"score_credito\"].dropna() # dropna exclui linhas vazias\n",
    "display(score_clientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supondo que esse array se trata do processamento e previsão que a IA fez, já temos os dados, falta formatá-los para uma forma mais legível, para isso utilizaremos um gráfico para vizualizar a proporção dos resultados e, em seguida, a OpenAI API para gerar relatórios mais específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "grafico = px.histogram(tabela, score_clientes)\n",
    "grafico.show()\n",
    "# Para um histogram no plotly precisamos passar dois parâmetros obrigatórios:\n",
    "# a base de dados completa e a coluna que queremos análisar.\n",
    "\n",
    "# Ele vai automaticamente associar com um outro parâmetro nativo chamado count (contagem dos dados)\n",
    "# Se a coluna tiver dados string, ele vai fazer como abaixo, contando os iguais e separando por colunas\n",
    "# os diferentes, caso os dados sejam number, ele vai adaptar de outra maneira, porém semelhante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aqui já temos uma vizualização melhor do comportamento dos clientes nesse quesito, mas ainda não temos um relatório completo, apenas uma quatificação mais visual, facilita uma possível apresentação dos dados, mas precisamos de um relatório mais detalhado. Agora faremos um filtro e uma adaptação com os dados para o que o modelo aprimorado da OpenAI possa trabalhar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_clientes = dict(zip(tabela.id_cliente, tabela.score_credito))\n",
    "display(score_clientes) \n",
    "# Aqui eu faço uma conversão mais avançada, associando o id dos clientes com\n",
    "# sua respectiva pontuação de créditos com a empresa. Isso será útil na geração de \n",
    "# relatório, uma vez que precisamos associar cliente com a pontuação para obter um bom desempenho \n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # Carregando .env\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") # Pegando chave de API do .env\n",
    "\n",
    "modelo = OpenAI(api_key=OPENAI_API_KEY) \n",
    "# Passando chave de API para o objeto que executará as tarefas com IA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agora, precisamos trabalhar com o prompt da IA para que assim, ela nos gere um relatório dizendo quais clientes devem receber o benefício e quais não estão aptos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamento = \"\"\"\n",
    "                Você é um modelo treinado para gerar relatórios com base em IDs, você sempre receberá um array de IDs e terá que gerar um relatório para eles em texto.\n",
    "                No atual contexto você presta serviços para uma empresa financeira que dará benefícios fiscais para os clientes que possuam nota de crédito boa.\n",
    "                Sua tarefa é gerar um padrão fixo de relatório detalhado, formal e culto, que contenha os IDs dos clientes elegíveis em lista, indicando que eles\n",
    "                receberão tal benefício. Lembre-se de formatar o texto corretamente.\n",
    "              \"\"\"\n",
    "\n",
    "chat = modelo.chat.completions.create(\n",
    "    model='gpt-5-nano',\n",
    "    messages=[\n",
    "        { \n",
    "            \"role\": \"system\",  \n",
    "            \"content\": treinamento\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Quem é você?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aqui criamos o chat com um modelo do ChatGPT e atrbuímos um treinamento para ele, isso facilita e amplifica a eficiência do serviço da IA. Agora precisamos passar os dados dos clientes e solicitar um relatório, mas para isso, os dados necessitam de um tratamento basico, para separar os dados que srão utilizados, dos que não serão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_clients = []\n",
    "for id, score in score_clientes.items():\n",
    "    if score == \"Good\":\n",
    "        good_clients.append(id)\n",
    "print(good_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apenas essas poucas linhas foram suficientes para tratar e segregar esses dados. Com os dados apurados, já podemos fazer a solicitação do relatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "          Me gere um relatório como você foi instruído para fazer, a seguir deixo um array dos clientes elegíveis ao benefício. Dados de apoio {good_clients}\n",
    "         \"\"\"\n",
    "chat = modelo.chat.completions.create(\n",
    "    model='gpt-5-nano',\n",
    "    messages=[\n",
    "        { \n",
    "            \"role\": \"system\",  \n",
    "            \"content\": treinamento\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(chat.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
